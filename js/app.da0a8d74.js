(function(){"use strict";var t={1682:function(t,e,n){var a=n(5130),o=n(6768);function i(t,e,n,a,i,r){const s=(0,o.g2)("AstroCanvas");return(0,o.uX)(),(0,o.Wv)(s)}var r=n(4232);const s=t=>((0,o.Qi)("data-v-6a196785"),t=t(),(0,o.jt)(),t),l={class:"AstroCanvas"},c={class:"percentage-value"},v=s((()=>(0,o.Lk)("span",{class:"percentage-label"},"loading data",-1)));function p(t,e,n,a,i,s){const p=(0,o.g2)("el-progress"),m=(0,o.g2)("el-text"),d=(0,o.g2)("el-slider");return(0,o.uX)(),(0,o.CE)("div",l,[(0,o.Lk)("canvas",{id:"canvas_1",class:"big_canvas",onClick:e[0]||(e[0]=(...e)=>t.clickCanvas&&t.clickCanvas(...e))}),(0,o.bF)(p,{class:"percentage-progress",type:"dashboard",style:(0,r.Tr)("display:"+(i.isComplete?"none":"block")),percentage:i.progress_percentage,status:i.progress_status},{default:(0,o.k6)((({percentage:t})=>[(0,o.Lk)("span",c,(0,r.v_)(t)+"%",1),v])),_:1},8,["style","percentage","status"]),(0,o.bF)(m,{class:"percentage-frame",type:i.msg_type,size:"large"},{default:(0,o.k6)((()=>[(0,o.eW)((0,r.v_)(i.canvas_status_msg),1)])),_:1},8,["type"]),(0,o.Lk)("div",{class:"slider",style:(0,r.Tr)("display:"+(i.isComplete?"block":"none"))},[(0,o.bF)(d,{modelValue:i.cur_frame,"onUpdate:modelValue":e[1]||(e[1]=t=>i.cur_frame=t),min:i.frame_start,max:i.frame_end,"show-input":"","show-tooltip":"",onChange:s.sliderChange},null,8,["modelValue","min","max","onChange"])],4)])}n(4114),n(6573),n(8100),n(7936),n(7467),n(4732),n(9577);var m=n(8776),d=n(2951),u=n(890);const _={uniforms:{u_size:{value:new m.Pq0(1,1,1)},u_renderstyle:{value:0},u_renderthreshold:{value:.5},u_clim:{value:new m.I9Y(1,1)},u_data:{value:null},u_data_static:{value:null},u_cmdata:{value:null},u_cmdata_green:{value:null}},vertexShader:'\n\n\t\tvarying vec4 v_nearpos;\n\t\tvarying vec4 v_farpos;\n\t\tvarying vec3 v_position;\n\n\t\tvoid main() {\n\t\t\t\t// Prepare transforms to map to "camera view". See also:\n\t\t\t\t// https://threejs.org/docs/#api/renderers/webgl/WebGLProgram\n\t\t\t\tmat4 viewtransformf = modelViewMatrix;\n\t\t\t\tmat4 viewtransformi = inverse(modelViewMatrix);\n\n\t\t\t\t// Project local vertex coordinate to camera position. Then do a step\n\t\t\t\t// backward (in cam coords) to the near clipping plane, and project back. Do\n\t\t\t\t// the same for the far clipping plane. This gives us all the information we\n\t\t\t\t// need to calculate the ray and truncate it to the viewing cone.\n\t\t\t\tvec4 position4 = vec4(position, 1.0);\n\t\t\t\tvec4 pos_in_cam = viewtransformf * position4;\n\n\t\t\t\t// Intersection of ray and near clipping plane (z = -1 in clip coords)\n\t\t\t\tpos_in_cam.z = -pos_in_cam.w;\n\t\t\t\tv_nearpos = viewtransformi * pos_in_cam;\n\n\t\t\t\t// Intersection of ray and far clipping plane (z = +1 in clip coords)\n\t\t\t\tpos_in_cam.z = pos_in_cam.w;\n\t\t\t\tv_farpos = viewtransformi * pos_in_cam;\n\n\t\t\t\t// Set varyings and output pos\n\t\t\t\tv_position = position;\n\t\t\t\tgl_Position = projectionMatrix * viewMatrix * modelMatrix * position4;\n\t\t}',fragmentShader:"\n\n\t\t\t\tprecision highp float;\n\t\t\t\tprecision mediump sampler3D;\n\n\t\t\t\tuniform vec3 u_size;\n\t\t\t\tuniform int u_renderstyle;\n\t\t\t\tuniform float u_renderthreshold;\n\t\t\t\tuniform vec2 u_clim;\n\n\t\t\t\tuniform sampler3D u_data;\n\t\t\t\tuniform sampler3D u_data_static;\n\t\t\t\tuniform sampler2D u_cmdata;\n\t\t\t\tuniform sampler2D u_cmdata_green;\n\n\t\t\t\tvarying vec3 v_position;\n\t\t\t\tvarying vec4 v_nearpos;\n\t\t\t\tvarying vec4 v_farpos;\n\n\t\t\t\t// The maximum distance through our rendering volume is sqrt(3).\n\t\t\t\tconst int MAX_STEPS = 887;\t// 887 for 512^3, 1774 for 1024^3\n\t\t\t\tconst int REFINEMENT_STEPS = 4;\n\t\t\t\tconst float relative_step_size = 1.0;\n\t\t\t\tconst vec4 ambient_color = vec4(0.2, 0.4, 0.2, 1.0);\n\t\t\t\tconst vec4 diffuse_color = vec4(0.8, 0.2, 0.2, 1.0);\n\t\t\t\tconst vec4 specular_color = vec4(1.0, 1.0, 1.0, 1.0);\n\t\t\t\tconst float shininess = 40.0;\n\n\t\t\t\tvoid cast_mip(vec3 start_loc, vec3 step, int nsteps, vec3 view_ray);\n\t\t\t\tvoid cast_iso(vec3 start_loc, vec3 step, int nsteps, vec3 view_ray);\n\n\t\t\t\tfloat sample1(vec3 texcoords);\n\t\t\t\tfloat sample1_static(vec3 texcoords);\n\n\t\t\t\tvec4 apply_colormap(float val);\n\t\t\t\tvec4 apply_colormap_static(float val);\n\t\t\t\tvec4 add_lighting(float val, vec3 loc, vec3 step, vec3 view_ray);\n\n\n\t\t\t\tvoid main() {\n\t\t\t\t\t\t// Normalize clipping plane info\n\t\t\t\t\t\tvec3 farpos = v_farpos.xyz / v_farpos.w;\n\t\t\t\t\t\tvec3 nearpos = v_nearpos.xyz / v_nearpos.w;\n\n\t\t\t\t\t\t// Calculate unit vector pointing in the view direction through this fragment.\n\t\t\t\t\t\tvec3 view_ray = normalize(nearpos.xyz - farpos.xyz);\n\n\t\t\t\t\t\t// Compute the (negative) distance to the front surface or near clipping plane.\n\t\t\t\t\t\t// v_position is the back face of the cuboid, so the initial distance calculated in the dot\n\t\t\t\t\t\t// product below is the distance from near clip plane to the back of the cuboid\n\t\t\t\t\t\tfloat distance = dot(nearpos - v_position, view_ray);\n\t\t\t\t\t\tdistance = max(distance, min((-0.5 - v_position.x) / view_ray.x,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t(u_size.x - 0.5 - v_position.x) / view_ray.x));\n\t\t\t\t\t\tdistance = max(distance, min((-0.5 - v_position.y) / view_ray.y,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t(u_size.y - 0.5 - v_position.y) / view_ray.y));\n\t\t\t\t\t\tdistance = max(distance, min((-0.5 - v_position.z) / view_ray.z,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t(u_size.z - 0.5 - v_position.z) / view_ray.z));\n\n\t\t\t\t\t\t// Now we have the starting position on the front surface\n\t\t\t\t\t\tvec3 front = v_position + view_ray * distance;\n\n\t\t\t\t\t\t// Decide how many steps to take\n\t\t\t\t\t\tint nsteps = int(-distance / relative_step_size + 0.5);\n\t\t\t\t\t\tif ( nsteps < 1 )\n\t\t\t\t\t\t\t\tdiscard;\n\n\t\t\t\t\t\t// Get starting location and step vector in texture coordinates\n\t\t\t\t\t\tvec3 step = ((v_position - front) / u_size) / float(nsteps);\n\t\t\t\t\t\tvec3 start_loc = front / u_size;\n\n\t\t\t\t\t\t// For testing: show the number of steps. This helps to establish\n\t\t\t\t\t\t// whether the rays are correctly oriented\n\t\t\t\t\t\t//'gl_FragColor = vec4(0.0, float(nsteps) / 1.0 / u_size.x, 1.0, 1.0);\n\t\t\t\t\t\t//'return;\n\n\t\t\t\t\t\tif (u_renderstyle == 0)\n\t\t\t\t\t\t\t\tcast_mip(start_loc, step, nsteps, view_ray);\n\t\t\t\t\t\telse if (u_renderstyle == 1)\n\t\t\t\t\t\t\t\tcast_iso(start_loc, step, nsteps, view_ray);\n\n\t\t\t\t\t\tif (gl_FragColor.a < 0.05)\n\t\t\t\t\t\t\t\tdiscard;\n\t\t\t\t}\n\n\n\t\t\t\tfloat sample1(vec3 texcoords) {\n\t\t\t\t\t\t/* Sample float value from a 3D texture. Assumes intensity data. */\n\t\t\t\t\t\treturn texture(u_data, texcoords.xyz).r;\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\tfloat sample1_static(vec3 texcoords) {\n\t\t\t\t\treturn texture(u_data_static, texcoords.xyz).r;\n\t\t\t\t}\n\n\t\t\t\tvec4 apply_colormap(float val) {\n\t\t\t\t\t\tval = (val - u_clim[0]) / (u_clim[1] - u_clim[0]);\n\n\t\t\t\t\t\treturn texture2D(u_cmdata_green, vec2(val, 0.5));\n\t\t\t\t\t\t// return texture2D(u_cmdata, vec2(val, 0.5));\n\t\t\t\t}\n\t\t\t\tvec4 apply_colormap_static(float val, float val_static) {\n\t\t\t\t\tif(val > val_static) {\n\t\t\t\t\t\t// val = val - val_static; // the effert is bad, so remove this line, although it is the right fluo density!\n\t\t\t\t\t\tval = (val - u_clim[0]) / (u_clim[1] - u_clim[0]);\n\t\t\t\t\t\treturn texture2D(u_cmdata_green, vec2(val, 0.5));\n\t\t\t\t\t} else {\n\t\t\t\t\t\tval = (val - u_clim[0]) / (u_clim[1] - u_clim[0]);\n\t\t\t\t\t\treturn texture2D(u_cmdata, vec2(val, 0.5));\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tvoid cast_mip(vec3 start_loc, vec3 step, int nsteps, vec3 view_ray) {\n\n\t\t\t\t\t\tfloat max_val = -1e6;\n\t\t\t\t\t\tfloat max_val_static = -1e6;\n\t\t\t\t\t\tint max_i = 100;\n\t\t\t\t\t\tvec3 loc = start_loc;\n\n\t\t\t\t\t\t// Enter the raycasting loop. In WebGL 1 the loop index cannot be compared with\n\t\t\t\t\t\t// non-constant expression. So we use a hard-coded max, and an additional condition\n\t\t\t\t\t\t// inside the loop.\n\t\t\t\t\t\tfor (int iter=0; iter<MAX_STEPS; iter++) {\n\t\t\t\t\t\t\t\tif (iter >= nsteps)\n\t\t\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t\t// Sample from the 3D texture\n\t\t\t\t\t\t\t\tfloat val = sample1(loc);\n\t\t\t\t\t\t\t\tfloat val_static = sample1_static(loc);\n\t\t\t\t\t\t\t\t// Apply MIP operation\n\t\t\t\t\t\t\t\tif (val > max_val) {\n\t\t\t\t\t\t\t\t\t\tmax_val = val;\n\t\t\t\t\t\t\t\t\t\tmax_i = iter;\n\t\t\t\t\t\t\t\t\t\tmax_val_static = val_static;\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t// Advance location deeper into the volume\n\t\t\t\t\t\t\t\tloc += step;\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\t// Refine location, gives crispier images\n\t\t\t\t\t\tvec3 iloc = start_loc + step * (float(max_i) - 0.5);\n\t\t\t\t\t\tvec3 istep = step / float(REFINEMENT_STEPS);\n\t\t\t\t\t\tfor (int i=0; i<REFINEMENT_STEPS; i++) {\n\t\t\t\t\t\t\t\tmax_val = max(max_val, sample1(iloc));\n\t\t\t\t\t\t\t\tmax_val_static = max(max_val_static, sample1_static(iloc));\n\t\t\t\t\t\t\t\tiloc += istep;\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\t// Resolve final color\n\t\t\t\t\t\tgl_FragColor = apply_colormap_static(max_val, max_val_static);\n\t\t\t\t}\n\n\n\t\t\t\tvoid cast_iso(vec3 start_loc, vec3 step, int nsteps, vec3 view_ray) {\n\n\t\t\t\t\t\tgl_FragColor = vec4(0.0);\t// init transparent\n\t\t\t\t\t\tvec4 color3 = vec4(0.0);\t// final color\n\t\t\t\t\t\tvec3 dstep = 1.5 / u_size;\t// step to sample derivative\n\t\t\t\t\t\tvec3 loc = start_loc;\n\n\t\t\t\t\t\tfloat low_threshold = u_renderthreshold - 0.02 * (u_clim[1] - u_clim[0]);\n\n\t\t\t\t\t\t// Enter the raycasting loop. In WebGL 1 the loop index cannot be compared with\n\t\t\t\t\t\t// non-constant expression. So we use a hard-coded max, and an additional condition\n\t\t\t\t\t\t// inside the loop.\n\t\t\t\t\t\tfor (int iter=0; iter<MAX_STEPS; iter++) {\n\t\t\t\t\t\t\t\tif (iter >= nsteps)\n\t\t\t\t\t\t\t\t\t\tbreak;\n\n\t\t\t\t\t\t\t\t// Sample from the 3D texture\n\t\t\t\t\t\t\t\tfloat val = sample1(loc);\n\n\t\t\t\t\t\t\t\tif (val > low_threshold) {\n\t\t\t\t\t\t\t\t\t\t// Take the last interval in smaller steps\n\t\t\t\t\t\t\t\t\t\tvec3 iloc = loc - 0.5 * step;\n\t\t\t\t\t\t\t\t\t\tvec3 istep = step / float(REFINEMENT_STEPS);\n\t\t\t\t\t\t\t\t\t\tfor (int i=0; i<REFINEMENT_STEPS; i++) {\n\t\t\t\t\t\t\t\t\t\t\t\tval = sample1(iloc);\n\t\t\t\t\t\t\t\t\t\t\t\tif (val > u_renderthreshold) {\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tgl_FragColor = add_lighting(val, iloc, dstep, view_ray);\n\t\t\t\t\t\t\t\t\t\t\t\t\t\treturn;\n\t\t\t\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\t\t\t\tiloc += istep;\n\t\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\t\t// Advance location deeper into the volume\n\t\t\t\t\t\t\t\tloc += step;\n\t\t\t\t\t\t}\n\t\t\t\t}\n\n\n\t\t\t\tvec4 add_lighting(float val, vec3 loc, vec3 step, vec3 view_ray)\n\t\t\t\t{\n\t\t\t\t\t// Calculate color by incorporating lighting\n\n\t\t\t\t\t\t// View direction\n\t\t\t\t\t\tvec3 V = normalize(view_ray);\n\n\t\t\t\t\t\t// calculate normal vector from gradient\n\t\t\t\t\t\tvec3 N;\n\t\t\t\t\t\tfloat val1, val2;\n\t\t\t\t\t\tval1 = sample1(loc + vec3(-step[0], 0.0, 0.0));\n\t\t\t\t\t\tval2 = sample1(loc + vec3(+step[0], 0.0, 0.0));\n\t\t\t\t\t\tN[0] = val1 - val2;\n\t\t\t\t\t\tval = max(max(val1, val2), val);\n\t\t\t\t\t\tval1 = sample1(loc + vec3(0.0, -step[1], 0.0));\n\t\t\t\t\t\tval2 = sample1(loc + vec3(0.0, +step[1], 0.0));\n\t\t\t\t\t\tN[1] = val1 - val2;\n\t\t\t\t\t\tval = max(max(val1, val2), val);\n\t\t\t\t\t\tval1 = sample1(loc + vec3(0.0, 0.0, -step[2]));\n\t\t\t\t\t\tval2 = sample1(loc + vec3(0.0, 0.0, +step[2]));\n\t\t\t\t\t\tN[2] = val1 - val2;\n\t\t\t\t\t\tval = max(max(val1, val2), val);\n\n\t\t\t\t\t\tfloat gm = length(N); // gradient magnitude\n\t\t\t\t\t\tN = normalize(N);\n\n\t\t\t\t\t\t// Flip normal so it points towards viewer\n\t\t\t\t\t\tfloat Nselect = float(dot(N, V) > 0.0);\n\t\t\t\t\t\tN = (2.0 * Nselect - 1.0) * N;\t// ==\tNselect * N - (1.0-Nselect)*N;\n\n\t\t\t\t\t\t// Init colors\n\t\t\t\t\t\tvec4 ambient_color = vec4(0.0, 0.0, 0.0, 0.0);\n\t\t\t\t\t\tvec4 diffuse_color = vec4(0.0, 0.0, 0.0, 0.0);\n\t\t\t\t\t\tvec4 specular_color = vec4(0.0, 0.0, 0.0, 0.0);\n\n\t\t\t\t\t\t// note: could allow multiple lights\n\t\t\t\t\t\tfor (int i=0; i<1; i++)\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t // Get light direction (make sure to prevent zero devision)\n\t\t\t\t\t\t\t\tvec3 L = normalize(view_ray);\t//lightDirs[i];\n\t\t\t\t\t\t\t\tfloat lightEnabled = float( length(L) > 0.0 );\n\t\t\t\t\t\t\t\tL = normalize(L + (1.0 - lightEnabled));\n\n\t\t\t\t\t\t\t\t// Calculate lighting properties\n\t\t\t\t\t\t\t\tfloat lambertTerm = clamp(dot(N, L), 0.0, 1.0);\n\t\t\t\t\t\t\t\tvec3 H = normalize(L+V); // Halfway vector\n\t\t\t\t\t\t\t\tfloat specularTerm = pow(max(dot(H, N), 0.0), shininess);\n\n\t\t\t\t\t\t\t\t// Calculate mask\n\t\t\t\t\t\t\t\tfloat mask1 = lightEnabled;\n\n\t\t\t\t\t\t\t\t// Calculate colors\n\t\t\t\t\t\t\t\tambient_color +=\tmask1 * ambient_color;\t// * gl_LightSource[i].ambient;\n\t\t\t\t\t\t\t\tdiffuse_color +=\tmask1 * lambertTerm;\n\t\t\t\t\t\t\t\tspecular_color += mask1 * specularTerm * specular_color;\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\t// Calculate final color by componing different components\n\t\t\t\t\t\tvec4 final_color;\n\t\t\t\t\t\tvec4 color = apply_colormap(val);\n\t\t\t\t\t\tfinal_color = color * (ambient_color + diffuse_color) + specular_color;\n\t\t\t\t\t\tfinal_color.a = color.a;\n\t\t\t\t\t\treturn final_color;\n\t\t\t\t}"};var f=n(4502),h=n(6729),g=n(2730);const w=new m.Z58;let y,x,b,z,k,C,L,S,E,N,T,A,F=new h.A;const P=.1*Math.PI;let I,M=!0,D=0,R=0,O=null;const V={animate:!0,rotate:!0};let j;var W={name:"AstroCanvas",data(){return{progress_percentage:0,isComplete:!1,canvas_status_msg:"loading..",frame_start:0,frame_end:10,cur_frame:0,progress_status:"",msg_type:"success"}},mounted(){O=this,this.init(),this.readIni()},methods:{init(){const t=1e3,e=window.innerWidth/window.innerHeight;x=new m.qUd(-t*e/2,t*e/2,t/2,-t/2,1,2e3),x.position.set(300,0,0);const n=document.querySelector("#canvas_1");y=new m.JeP({canvas:n}),y.setPixelRatio(1),y.setSize(window.innerWidth,window.innerHeight,!1),b=new d.N(x,y.domElement),b.minZoom=.5,b.maxZoom=100,x.zoom=4,x.updateProjectionMatrix(),b.enablePan=!1,b.update(),E=new m.YJl,window.addEventListener("resize",this.onWindowResize)},sliderChange(){this.innerAnimate()},async readIni(){await fetch("dynamics.ini").then((t=>t.text())).then((t=>{let e=(0,g.parse)(t);I=e[e.active],O.frame_start=parseInt(I.frame_start),O.frame_end=parseInt(I.frame_end),O.cur_frame=O.frame_start,j=new Array(O.frame_end-O.frame_start+1),V.animate=I.animate,V.rotate=I.rotate})),this.preloadData()},drawAxis(){const t=new m.IzY(200);w.add(t)},innerRotate(){V.rotate&&(M?(E.rotation.y+=.005,E.rotation.y>P&&(M=!1)):(E.rotation.y-=.005,E.rotation.y<-P&&(M=!0)))},render(){y.render(w,x),requestAnimationFrame(this.render)},onWindowResize(){y.setSize(window.innerWidth,window.innerHeight);const t=window.innerWidth/window.innerHeight,e=x.top-x.bottom;x.left=-e*t/2,x.right=e*t/2,x.updateProjectionMatrix()},drawCenterCube(){let t=new m.iNn(10,10,10),e=new m.V9B({color:65280,side:m.$EB}),n=new m.eaF(t,e);E.add(n),n.position.set(30,260,260),w.add(E)},loadData(){N={viridis:(new m.Tap).load("colormap/cm_viridis.png",(function(){y.render(w,x)})),gray:(new m.Tap).load("colormap/cm_gray.png",(function(){y.render(w,x)})),green:(new m.Tap).load("colormap/cm_green.png",(function(){y.render(w,x)})),mix:(new m.Tap).load("colormap/cm_mix.png",(function(){y.render(w,x)}))},T={clim1:0,clim2:1,renderstyle:"mip",isothreshold:0,colormap:"mix",frame:10},L=new f.w,L.load("dynamics/"+I.nrrd_file,this.loadVolume);const t=new u.cL;t.add(V,"animate").onChange(this.updateAnimate),t.add(V,"rotate").onChange(this.updateRotate),t.add(T,"clim1",0,.5,.01).onChange(this.updateUniforms)},updateAnimate(t){V.animate=t},updateRotate(t){V.rotate=t},async preloadData(){let t=[];for(let o=this.frame_start;o<=this.frame_end;o++){let e="dynamics/"+I.frame_prefix+String(o).padStart(5,"0")+".npy";t.push(e)}const e=[...t];async function n(t,n){return new Promise((a=>{const o=[],i=async r=>{try{const t=e.indexOf(r);await fetch(r).then((t=>t.ok?(D++,t.arrayBuffer()):(R++,O.progress_status="exception",O.msg_type="danger",O.canvas_status_msg="URL: "+r+"\tCode:"+t.status+"\t"+t.statusText,null))).then((n=>{0==R&&null!=n&&(j[t]=n,O.progress_percentage=Math.floor(D/(e.length+1)*100))}))}catch(s){R++,O.progress_status="exception",O.canvas_status_msg=s.message,O.msg_type="danger"}finally{const t=o.indexOf(r);-1!==t&&o.splice(t,1)}if(0==R&&t.length>0&&o.length<n){const e=t.shift();i(e),o.push(e)}0===t.length&&0===o.length&&a(D)};for(let e=0;e<Math.min(n,t.length);e++){const e=t.shift();i(e),o.push(e)}}))}const a=10;n(t,a).then((t=>{t==e.length&&O.loadData()})).catch((t=>{console.error("err：",t)}))},loadVolume(t){this.progress_percentage=100,A=new Float32Array(t.data),k=new m.dYF(t.data,t.xLength,t.yLength,t.zLength),k.format=m.VT0,k.type=m.RQf,k.minFilter=k.magFilter=m.k6q,k.unpackAlignment=1,k.needsUpdate=!0,C=new m.dYF(t.data,t.xLength,t.yLength,t.zLength),C.format=m.VT0,C.type=m.RQf,C.minFilter=C.magFilter=m.k6q,C.unpackAlignment=1,C.needsUpdate=!0;const e=_,n=m.LlO.clone(e.uniforms);n["u_data"].value=k,n["u_data_static"].value=C,n["u_size"].value.set(t.xLength,t.yLength,t.zLength),n["u_clim"].value.set(T.clim1,T.clim2),n["u_renderstyle"].value=0,n["u_renderthreshold"].value=T.isothreshold,n["u_cmdata"].value=N["gray"],n["u_cmdata_green"].value=N["viridis"],z=new m.BKk({uniforms:n,vertexShader:e.vertexShader,fragmentShader:e.fragmentShader,side:m.$EB});const a=new m.iNn(t.xLength,t.yLength,t.zLength);a.translate(t.xLength/2-.5,t.yLength/2-.5,t.zLength/2-.5),S=new m.eaF(a,z),S.position.set(-t.xLength/2,-t.yLength/2,-t.zLength/2),E.add(S),w.add(E),this.isComplete=!0,this.render(),setInterval(this.frameAnimate,50,this)},updateUniforms(){z.uniforms["u_clim"].value.set(T.clim1,T.clim2)},innerAnimate(){F.load(j[this.cur_frame-this.frame_start],(t=>{let e=t.shape[0],n=new Float32Array(A);for(let a=0;a<e;a+=2)n[t.data[a]]+=t.data[a+1]/1e6;z.uniforms["u_data"].value.needsUpdate=!0,z.uniforms["u_data"].value.image.data=n,O.canvas_status_msg="current frame: "+String(this.cur_frame)}))},frameAnimate(){this.innerRotate(),V.animate&&(this.cur_frame=this.cur_frame+1,this.cur_frame>this.frame_end&&(this.cur_frame=this.frame_start),this.innerAnimate())}}},U=n(1241);const q=(0,U.A)(W,[["render",p],["__scopeId","data-v-6a196785"]]);var H=q,B={name:"App",components:{AstroCanvas:H}};const G=(0,U.A)(B,[["render",i]]);var X=G,Y=n(9757);n(4188);(0,a.Ef)(X).use(Y.A).mount("#app")}},e={};function n(a){var o=e[a];if(void 0!==o)return o.exports;var i=e[a]={exports:{}};return t[a].call(i.exports,i,i.exports,n),i.exports}n.m=t,function(){var t=[];n.O=function(e,a,o,i){if(!a){var r=1/0;for(v=0;v<t.length;v++){a=t[v][0],o=t[v][1],i=t[v][2];for(var s=!0,l=0;l<a.length;l++)(!1&i||r>=i)&&Object.keys(n.O).every((function(t){return n.O[t](a[l])}))?a.splice(l--,1):(s=!1,i<r&&(r=i));if(s){t.splice(v--,1);var c=o();void 0!==c&&(e=c)}}return e}i=i||0;for(var v=t.length;v>0&&t[v-1][2]>i;v--)t[v]=t[v-1];t[v]=[a,o,i]}}(),function(){n.n=function(t){var e=t&&t.__esModule?function(){return t["default"]}:function(){return t};return n.d(e,{a:e}),e}}(),function(){n.d=function(t,e){for(var a in e)n.o(e,a)&&!n.o(t,a)&&Object.defineProperty(t,a,{enumerable:!0,get:e[a]})}}(),function(){n.g=function(){if("object"===typeof globalThis)return globalThis;try{return this||new Function("return this")()}catch(t){if("object"===typeof window)return window}}()}(),function(){n.o=function(t,e){return Object.prototype.hasOwnProperty.call(t,e)}}(),function(){var t={524:0};n.O.j=function(e){return 0===t[e]};var e=function(e,a){var o,i,r=a[0],s=a[1],l=a[2],c=0;if(r.some((function(e){return 0!==t[e]}))){for(o in s)n.o(s,o)&&(n.m[o]=s[o]);if(l)var v=l(n)}for(e&&e(a);c<r.length;c++)i=r[c],n.o(t,i)&&t[i]&&t[i][0](),t[i]=0;return n.O(v)},a=self["webpackChunkastro_dynamics"]=self["webpackChunkastro_dynamics"]||[];a.forEach(e.bind(null,0)),a.push=e.bind(null,a.push.bind(a))}();var a=n.O(void 0,[504],(function(){return n(1682)}));a=n.O(a)})();
//# sourceMappingURL=app.da0a8d74.js.map